#! /usr/bin/env nix
#! nix develop --command python

"""
Generate a Buck2 rules.bzl file for Boost header-only libraries.

Downloads and extracts a Boost release tarball, discovers all modules
(subdirectories under boost/), and generates prebuilt_cxx_library rules.

Usage:
    python generate_rules.py <url> [--sha256 <hash>] [--output rules.bzl] [--modules mod1,mod2,...]

Examples:
    python generate_rules.py \
        https://github.com/boostorg/boost/releases/download/boost-1.88.0/boost-1.88.0-b2-nodocs.tar.gz \
        --sha256 85138e4a185a7e7535e82b011179c5b5fb72185bea9f59fe8e2d76939b2f5c51

    # Only include specific modules:
    python generate_rules.py <url> --modules uuid,range,geometry
"""

import argparse
import hashlib
import os
import sys
import tarfile
import tempfile
import urllib.request
from pathlib import Path


def download_and_extract(url: str, dest: Path, expected_sha256=None) -> Path:
    """Download a tarball from url, verify its hash, and extract it. Returns the boost/ include root."""
    tarball = dest / "boost.tar.gz"
    print(f"Downloading {url} ...")
    urllib.request.urlretrieve(url, tarball)

    if expected_sha256:
        print("Verifying SHA-256 ...")
        sha = hashlib.sha256()
        with open(tarball, "rb") as f:
            for chunk in iter(lambda: f.read(1 << 20), b""):
                sha.update(chunk)
        actual = sha.hexdigest()
        if actual != expected_sha256:
            print(
                f"SHA-256 mismatch!\n  expected: {expected_sha256}\n  actual:   {actual}",
                file=sys.stderr,
            )
            sys.exit(1)
        print("SHA-256 OK")

    print("Extracting ...")
    with tarfile.open(tarball, "r:gz") as tf:
        tf.extractall(dest)

    # Find the boost/ include directory inside the extracted tree.
    # Typically it's <strip_prefix>/boost/
    for entry in sorted(dest.iterdir()):
        candidate = entry / "boost"
        if candidate.is_dir():
            return entry  # the root that contains boost/
    print("Could not find boost/ directory in the archive", file=sys.stderr)
    sys.exit(1)


def discover_modules(
    boost_include_root: Path,
) -> tuple[dict[str, list[str]], list[str]]:
    """
    Walk boost/ and return:
      - modules: dict mapping module_name -> list of header paths (relative to include root)
      - loose_headers: list of header files directly in boost/ (not in any subdirectory)
    """
    boost_dir = boost_include_root / "boost"
    modules: dict[str, list[str]] = {}
    loose_headers: list[str] = []

    # Collect loose files directly in boost/
    for f in sorted(boost_dir.iterdir()):
        if f.is_file():
            loose_headers.append(f"boost/{f.name}")

    # Collect module directories
    for entry in sorted(boost_dir.iterdir()):
        if entry.is_dir():
            module_name = entry.name
            headers = []
            for root, _dirs, files in os.walk(entry):
                for fname in sorted(files):
                    full = Path(root) / fname
                    rel = full.relative_to(boost_include_root)
                    headers.append(str(rel))
            if headers:
                modules[module_name] = sorted(headers)

    return modules, loose_headers


def format_header_list(headers: list[str]) -> str:
    """Format a list of header paths as a comma-separated quoted string."""
    return ",".join(f'"{h}"' for h in headers)


def generate_bzl(
    url: str,
    sha256,
    strip_prefix: str,
    archive_name: str,
    modules: dict[str, list[str]],
    loose_headers: list[str],
) -> str:
    """Generate the full rules.bzl content."""
    lines: list[str] = []

    # Header comment
    lines.append("# AUTO-GENERATED by generate_rules.py â€” do not edit manually")
    lines.append("")

    # Variable names for each module
    var_names: dict[str, str] = {}
    for mod in modules:
        var_name = f"_BOOST_{mod.upper()}"
        var_names[mod] = var_name

    # Emit file lists for each module
    for mod, headers in modules.items():
        var = var_names[mod]
        lines.append(f"{var} = [")
        lines.append(f"    {format_header_list(headers)}")
        lines.append("];")
        lines.append("")

    # http_archive rule
    lines.append("http_archive(")
    lines.append(f'    name = "{archive_name}",')
    lines.append(f'    urls = ["{url}"],')
    if sha256:
        lines.append(f"    sha256 = '{sha256}',")
    lines.append(f'    strip_prefix = "{strip_prefix}",')
    lines.append('    type="tar.gz",')

    # sub_targets: all module lists + loose headers
    mod_list = list(modules.keys())
    if mod_list:
        lines.append(f"    sub_targets = {var_names[mod_list[0]]}")
        for mod in mod_list[1:]:
            lines.append(f"        + {var_names[mod]}")

    if loose_headers:
        lines.append("        + [")
        for h in loose_headers:
            lines.append(f'            "{h}",')
        lines.append("        ]")

    lines.append(")")
    lines.append("")

    # Per-module prebuilt_cxx_library rules
    for mod in modules:
        var = var_names[mod]
        lines.append("prebuilt_cxx_library(")
        lines.append(f'    name = "boost.{mod}",')
        lines.append("    header_only = True,")
        lines.append("    exported_headers = {")
        lines.append(f'        p: ":{archive_name}[{{}}]".format(p) for p in {var}')
        lines.append("    },")
        lines.append('    header_namespace = "",')
        lines.append('    visibility = ["PUBLIC"]')
        lines.append(")")
        lines.append("")

    # Top-level "boost" library that re-exports everything
    lines.append("prebuilt_cxx_library(")
    lines.append('    name = "boost",')
    lines.append("    header_only = True,")

    if loose_headers:
        lines.append("    exported_headers = {")
        for h in loose_headers:
            lines.append(f'        "{h}": ":{archive_name}[{h}]",')
        lines.append("    },")

    lines.append("    exported_deps = [")
    for mod in modules:
        lines.append(f'        ":boost.{mod}",')
    lines.append("    ],")
    lines.append('    header_namespace = "",')
    lines.append('    visibility = ["PUBLIC"]')
    lines.append(")")
    lines.append("")

    return "\n".join(lines)


def main():
    parser = argparse.ArgumentParser(description="Generate Buck2 rules.bzl for Boost")
    parser.add_argument("url", help="URL of the Boost tarball")
    parser.add_argument(
        "--sha256", default=None, help="Expected SHA-256 of the tarball"
    )
    parser.add_argument(
        "--output", default="rules.bzl", help="Output file path (default: rules.bzl)"
    )
    parser.add_argument(
        "--modules",
        default=None,
        help="Comma-separated list of module names to include (default: all)",
    )
    args = parser.parse_args()

    # Infer strip_prefix and archive_name from URL
    # e.g. .../boost-1.88.0-b2-nodocs.tar.gz -> strip_prefix=boost-1.88.0
    basename = args.url.rsplit("/", 1)[-1]  # boost-1.88.0-b2-nodocs.tar.gz
    # Try to extract version: boost-X.Y.Z
    parts = basename.split("-")
    if len(parts) >= 2:
        # "boost", "1.88.0", ...
        version = parts[1]
        strip_prefix = f"boost-{version}"
        archive_name = f"boost-{version}.raw"
    else:
        strip_prefix = basename.replace(".tar.gz", "").replace(".tgz", "")
        archive_name = f"{strip_prefix}.raw"

    with tempfile.TemporaryDirectory() as tmpdir:
        root = download_and_extract(args.url, Path(tmpdir), args.sha256)
        modules, loose_headers = discover_modules(root)

    # Filter modules if requested
    if args.modules:
        wanted = set(args.modules.split(","))
        modules = {k: v for k, v in modules.items() if k in wanted}
        missing = wanted - set(modules.keys())
        if missing:
            print(
                f"Warning: requested modules not found: {', '.join(sorted(missing))}",
                file=sys.stderr,
            )

    print(f"Found {len(modules)} modules and {len(loose_headers)} loose headers")

    bzl = generate_bzl(
        url=args.url,
        sha256=args.sha256,
        strip_prefix=strip_prefix,
        archive_name=archive_name,
        modules=modules,
        loose_headers=loose_headers,
    )

    with open(args.output, "w") as f:
        f.write(bzl)

    print(f"Written to {args.output}")


if __name__ == "__main__":
    main()
